---
title: "Preprocessing for SSF"
format: html
editor: visual
---

```{r}
# Load necessary packages -----------------------------------------------------
pacman::p_load(
  tidyverse,
  amt
)

options(scipen = 999) # turn off scientific notation
options(digits = 15) # set digits to 15 to ensure GPS coordinates aren't truncated

# Load and prepare tracking data ---------------------------------------------
tracking_data <- read_delim("data/bobcat_coyotes_wa_gps.csv") |> 
  dplyr::rename(
    long = `location-long`, 
    lat = `location-lat`,
    id = `individual-local-identifier`,
    timestamp = `timestamp`,
    species = `individual-taxon-canonical-name`) |> 
  dplyr::arrange(id, timestamp) |> 
  dplyr::select(id, species, timestamp, lat, long) |> 
  dplyr::filter(!(id == "MVBOB71M" & timestamp > as.POSIXct("2019-09-24 00:00:00")))

# Create and inspect tracks ---------------------------------------------------
track <- tracking_data |>
  nest(data = c(-id, -species)) |>
  mutate(trk = map(data, ~ make_track(.x, long, lat, timestamp, crs = 4326)))

# Summarize sampling rate
trackSummary <- track |> 
  mutate(sr = lapply(trk, summarize_sampling_rate, time_unit = "hour")) |> 
  dplyr::select(id, sr) |> 
  unnest(cols = sr) |>
  left_join(distinct(dplyr::select(tracking_data, id, species))) |>
  arrange(species, median)

# Get the individual sampling rates instead of the summary, for plotting.
trackSummarySamples <- track |>
  mutate(sr = lapply(trk, summarize_sampling_rate, time_unit = "hour", summarize = FALSE)) |>
  dplyr::select(id, sr) |>
  unnest(cols = sr) |>
  mutate(species = ifelse(grepl("BOB", id), "Bobcat", "Coyote"))

png("img/bobcat_coyote_sampling_rates.png")
boxplot(sr ~ species, outline = FALSE, data = trackSummarySamples, 
        xlab = "", 
        ylab = "Sampling interval in hours")
dev.off()

png("img/bobcat_coyote_sampling_rates_outliers.png")
boxplot(sr ~ species, outline = TRUE, data = trackSummarySamples, 
        xlab = "", 
        ylab = "Sampling interval in hours")
dev.off()

# Split into species ----------------------------------------------------------
coyote <- filter(track, grepl("COY", id))
bobcat <- filter(track, grepl("BOB", id))

# Step generation for SSF -----------------------------------------------------
coyote1 <- coyote[-c(8, 19), ] |> # omitting coyote in row 8 and 19; too few consecutive data points - causing function to fail
  mutate(stp = map(trk, function(df)
    df |> 
      track_resample(rate = hours(4), tolerance = minutes(10)) |> 
      steps_by_burst() |> 
      random_steps(n_control = 10) %>% 
      mutate(log_sl_ = log(sl_ + 1), cos_ta_ = cos(ta_)))) |> 
  dplyr::select(-data, -trk) |> 
  unnest(cols = stp) |> 
  mutate(case_binary_ = ifelse(case_ == TRUE, 1, 0))

bobcat1 <- bobcat[-c(15, 18), ] |> # omitting bobcat in row 15 and 18; too few consecutive data points - causing function to fail
  mutate(stp = map(trk, function(df)
    df |> 
      track_resample(rate = hours(8), tolerance = minutes(10)) |> 
      steps_by_burst() |>  
      random_steps(n_control = 10) |> 
      mutate(log_sl_ = log(sl_ + 1), cos_ta_ = cos(ta_)))) |> 
  dplyr::select(-data, -trk) |> 
  unnest(cols = stp) |> 
  mutate(case_binary_ = ifelse(case_ == TRUE, 1, 0))

# Export resampled step data
write_csv(coyote1, "data/coyote_resampled.csv")
write_csv(bobcat1, "data/bobcat_resampled.csv")

# Read and recalculate step length (in meters) --------------------------------
recalc_steps <- function(file) {
  read_delim(file) |>
    dplyr::select(-log_sl_, -sl_) |>
    mutate(
      sl_ = distGeo(across(c(x1_, y1_)), across(c(x2_, y2_))),
      log_sl_ = log(sl_)
    )
}

coyote_resampled <- recalc_steps("data/coyote_resampled.csv")
bobcat_resampled <- recalc_steps("data/bobcat_resampled.csv")

# Load and prepare rasters ----------------------------------------------------
hfp <- rast("data/HFP_washington.tif")
NAflag(hfp) <- 64536  # Set no-data value
hfp_capped <- classify(hfp, matrix(c(50000, Inf, 50000), ncol = 3, byrow = TRUE)) # Cap at 50k
hfp_scaled <- app(hfp_capped, \(x) (x / 50000) - 0.5)  # Scale to -0.5â€“0.5

land_use <- rast("data/ESA_washington.tif")

# Land use class labels (ESA WorldCover 2021)
esa_labels <- c(
  "10" = "Tree cover", "20" = "Shrubland", "30" = "Grassland",
  "40" = "Cropland", "50" = "Built-up", "60" = "Bare or sparse vegetation",
  "70" = "Snow and ice", "80" = "Permanent water bodies",
  "90" = "Herbaceous wetland", "95" = "Mangroves", "100" = "Moss and lichen"
)

# Extract covariates from rasters ---------------------------------------------
extract_covariates <- function(df) {
  df |>
    mutate(
      human_footprint = terra::extract(hfp_scaled, cbind(x2_, y2_))[, 1],
      land_use_code = terra::extract(land_use, cbind(x2_, y2_))[, 1],
      land_use = factor(land_use_code, levels = names(esa_labels), labels = esa_labels)
    )
}

coyote_cov <- extract_covariates(coyote_resampled)
bobcat_cov <- extract_covariates(bobcat_resampled)

# Final formatting for SSF ----------------------------------------------------
prepare_ssf_data <- function(df) {
  df |>
    mutate(
      land_use = as.factor(land_use),
      land_use_grouped = fct_collapse(
        land_use,
        "TreeCover" = "Tree cover",
        "Open"      = c("Grassland", "Bare or sparse vegetation", "Moss and lichen"),
        "Cropland"  = "Cropland",
        "BuiltUp"   = "Built-up",
        "Water"     = c("Permanent water bodies", "Herbaceous wetland")
      ),
      step_id_ = paste(id, step_id_, sep = "_") # Unique stratum ID
    ) |>
    group_by(id) |>
    mutate(n = n() / 11) |> # 1 used + 10 available steps per stratum
    ungroup()
}

coyote_final <- prepare_ssf_data(coyote_cov)
bobcat_final <- prepare_ssf_data(bobcat_cov)

# Save final data
write_csv(coyote_final, "data/coyote_ssf_data.csv")
write_csv(bobcat_final, "data/bobcat_ssf_data.csv")
```

